# Home Sales on Spark
 week 22  
 
In this challenge, we use your SparkSQL in Google Colab environment to determine key metrics about home sales data. We use Spark to create temporary views, partition the data, cache and uncache a temporary table to compare the performances of the queries, and finally verify that the table has been uncached.

<img src='./img/colab.png' title='Google colab' width=150 height=100/> <img src='./img/spark.png' title='Apache Spark' width=150 height=100/>
